{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subproject C: \n",
    "\n",
    "Implement an additional bit of preprocessing that strips out periods (.), commas (,), colons (:), semi- colons (;), single quotes (’), exclamation points (!), or questions marks (?), but only if they are the first or last character of the word (this will leave contractions like “can’t” or “won’t” unaffected). You may notice that in doing so, you have to intrinsically discard all words that have only 1 character; do that as well. Submit the resulting top 40 words. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fisrt, import some Spark classes into the program, and create a SparkContext object, which tells Spark how to access a cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = SparkConf().setAppName('word count').setMaster('local[3]')\n",
    "sc = SparkContext(conf = conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an RDD by referencing datasets in an external storage system. We pass all file paths together (with wildcards), as we are going to count the words across all documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = sc.textFile('./data/4300-0.txt,./data/pg*.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an RDD for the stopwords, and use the broadcast variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoplist = sc.textFile('./data/stopwords.txt')\n",
    "broadcastStopList = sc.broadcast(set(stoplist.collect()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an RDD for the leading or trailing punctuations, which need to be stripped out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuations = sc.broadcast(set(\".,:;'!?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'!', \"'\", ',', '.', ':', ';', '?'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punctuations.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split each line into a list of words  \n",
    "Filter out the words which are in the stopwords list  \n",
    "Map each word, w, to a tuple, (w, 1)  \n",
    "Add the tuples with the same key (word)  \n",
    "Stripping the words which have leading or trailing punctuations  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = lines.flatMap(lambda line : line.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative way to strip out the heading or trailing punctuations\n",
    "\n",
    "filteredPunctuation = words.map(lambda word : word[1:] if len(word) > 0 and word[0] in punctuations.value else word).map(lambda word : word[:-1] if len(word) > 0 and word[-1] in punctuations.value else word)\n",
    "filteredWords = filteredPunctuation.filter(lambda word : word.lower() not in broadcastStopList.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "filteredWords = words.filter(lambda word : word.lower() not in broadcastStopList.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = filteredWords.map(lambda word : (word.lower(), 1)).reduceByKey(lambda a, b : a + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts2 = counts.map(lambda x : (x[0][1:], x[1]) if len(x[0]) > 1 and x[0][0] in punctuations.value else x).map(lambda x : (x[0][:-1], x[1]) if len(x[0]) > 1 and x[0][-1] in punctuations.value else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = counts2.filter(lambda x : x[1] > 2 and len(x[0]) > 1).takeOrdered(40, key=lambda x : -x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('not', 8141),\n",
       " ('you', 6354),\n",
       " ('have', 5146),\n",
       " ('no', 3620),\n",
       " ('one', 3498),\n",
       " ('like', 2253),\n",
       " ('more', 2087),\n",
       " ('out', 2021),\n",
       " ('up', 1831),\n",
       " ('man', 1783),\n",
       " ('now', 1579),\n",
       " ('only', 1555),\n",
       " ('must', 1523),\n",
       " ('little', 1485),\n",
       " ('those', 1447),\n",
       " ('good', 1444),\n",
       " ('should', 1417),\n",
       " ('after', 1379),\n",
       " ('great', 1358),\n",
       " ('every', 1356),\n",
       " ('first', 1318),\n",
       " ('own', 1289),\n",
       " ('did', 1271),\n",
       " ('how', 1266),\n",
       " ('see', 1251),\n",
       " ('these', 1244),\n",
       " ('men', 1233),\n",
       " ('over', 1209),\n",
       " ('where', 1205),\n",
       " ('make', 1196),\n",
       " ('upon', 1188),\n",
       " ('nor', 1181),\n",
       " ('never', 1177),\n",
       " ('much', 1167),\n",
       " ('time', 1166),\n",
       " ('said', 1163),\n",
       " ('two', 1142),\n",
       " ('old', 1140),\n",
       " ('made', 1128),\n",
       " ('most', 1114)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = dict(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sp3.json', 'w') as outfile:\n",
    "    json.dump(output, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
